{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# **Stories Modeling Preprocessing**\n\nSeparate notebook for model-ready preprocessing: cleaning alignment, encoding, normalization, train/test split, and baseline models."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **Load Cleaned Data**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nBASE_PATH = Path('/Users/mohamad22/Desktop/EECE_490_hackathon/Archive/Stories_data/cleaned')\nif not BASE_PATH.exists():\n    if Path('./cleaned').exists():\n        BASE_PATH = Path('./cleaned')\n    else:\n        BASE_PATH = Path('./Archive/Stories_data/cleaned')\n\nprint(f'Using data folder: {BASE_PATH.resolve()}')\n\ndf_month_long = pd.read_csv(BASE_PATH / 'rep_00134_comparative_monthly_sales_clean_long.csv')\nprint('monthly_sales_long shape:', df_month_long.shape)\ndf_month_long.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **Modeling-Ready Preprocessing (Encoding + Normalization)**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 1) Build modeling table\n# Target: sales_amount (branch-month level)\ndf_model = df_month_long[\n    (df_month_long['row_type'] == 'branch') &\n    (df_month_long['period_type'] == 'month')\n].copy()\n\n# Ensure month_number is populated\nmonth_map = {\n    'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5, 'june': 6,\n    'july': 7, 'august': 8, 'september': 9, 'october': 10, 'november': 11, 'december': 12\n}\ndf_model['period'] = df_model['period'].astype(str).str.lower().str.strip()\ndf_model['month_number'] = pd.to_numeric(df_model['month_number'], errors='coerce')\ndf_model['month_number'] = df_model['month_number'].fillna(df_model['period'].map(month_map))\n\n# Optional time feature\ndf_model['quarter'] = ((df_model['month_number'] - 1) // 3 + 1).astype('Int64')\n\n# 2) Features / target\nfeature_cols = ['branch', 'period', 'year', 'month_number', 'quarter']\ntarget_col = 'sales_amount'\n\nX = df_model[feature_cols].copy()\ny = pd.to_numeric(df_model[target_col], errors='coerce')\n\n# Drop rows with missing target\nvalid_idx = y.notna()\nX = X.loc[valid_idx]\ny = y.loc[valid_idx]\n\n# 3) Train/test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\ncat_cols = ['branch', 'period']\nnum_cols = ['year', 'month_number', 'quarter']\n\n# 4) Preprocessor for scale-sensitive models (ENCODING + NORMALIZATION)\npreprocessor_scaled = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), num_cols),\n        ('cat', Pipeline([\n            ('imputer', SimpleImputer(strategy='most_frequent')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), cat_cols),\n    ]\n)\n\n# 5) Preprocessor for tree models (ENCODING only, no normalization)\npreprocessor_tree = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median'))\n        ]), num_cols),\n        ('cat', Pipeline([\n            ('imputer', SimpleImputer(strategy='most_frequent')),\n            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n        ]), cat_cols),\n    ]\n)\n\n# 6) Example models\nridge_model = Pipeline([\n    ('prep', preprocessor_scaled),\n    ('model', Ridge(alpha=1.0))\n])\n\nrf_model = Pipeline([\n    ('prep', preprocessor_tree),\n    ('model', RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n])\n\nridge_model.fit(X_train, y_train)\nrf_model.fit(X_train, y_train)\n\npred_ridge = ridge_model.predict(X_test)\npred_rf = rf_model.predict(X_test)\n\nprint('Rows used for modeling:', len(df_model))\nprint('Train rows:', len(X_train), '| Test rows:', len(X_test))\nprint('Ridge  | MAE:', round(mean_absolute_error(y_test, pred_ridge), 2), '| R2:', round(r2_score(y_test, pred_ridge), 4))\nprint('RF     | MAE:', round(mean_absolute_error(y_test, pred_rf), 2), '| R2:', round(r2_score(y_test, pred_rf), 4))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## **Notes**\n\n- Use `preprocessor_scaled` for models sensitive to scale (linear models, SVM, KNN, PCA).\n- Use `preprocessor_tree` for tree models (Random Forest / XGBoost style), where scaling is typically unnecessary.\n- Keep all preprocessing inside pipelines to avoid data leakage."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}